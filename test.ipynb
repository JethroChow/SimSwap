{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f2d743b4-d151-4bd5-8dc2-3c7afa150c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import sys\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "151d892c-03d5-4097-9901-d64672e96c9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data1/tides/new/miniconda3/envs/faceSwap/lib/python3.8/site-packages/albumentations/__init__.py:13: UserWarning: A new version of Albumentations is available: 1.4.24 (you have 1.4.18). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n",
      "  check_for_updates()\n"
     ]
    }
   ],
   "source": [
    "from util.load_models import load_netArc, load_face_swap_model, load_insightface_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "db3c0541-e41f-45c4-9e73-c85bd801824b",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e047a555-34d8-4640-919e-2d0eb41bfd61",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------ Options -------------\n",
      "Arc_path: arcface_model/arcface_checkpoint.tar\n",
      "aspect_ratio: 1.0\n",
      "batchSize: 8\n",
      "checkpoints_dir: ./checkpoints\n",
      "cluster_path: features_clustered_010.npy\n",
      "crop_size: 512\n",
      "data_type: 32\n",
      "dataroot: ./datasets/cityscapes/\n",
      "display_winsize: 512\n",
      "engine: None\n",
      "export_onnx: None\n",
      "feat_num: 3\n",
      "fineSize: 512\n",
      "fp16: False\n",
      "gpu_ids: [0]\n",
      "how_many: 50\n",
      "id_thres: 0.03\n",
      "image_size: 224\n",
      "input_nc: 3\n",
      "instance_feat: False\n",
      "isTrain: False\n",
      "label_feat: False\n",
      "label_nc: 0\n",
      "latent_size: 512\n",
      "loadSize: 1024\n",
      "load_features: False\n",
      "local_rank: 0\n",
      "max_dataset_size: inf\n",
      "multisepcific_dir: ./demo_file/multispecific\n",
      "nThreads: 2\n",
      "n_blocks_global: 6\n",
      "n_blocks_local: 3\n",
      "n_clusters: 10\n",
      "n_downsample_E: 4\n",
      "n_downsample_global: 3\n",
      "n_local_enhancers: 1\n",
      "name: people\n",
      "nef: 16\n",
      "netG: global\n",
      "ngf: 64\n",
      "niter_fix_global: 0\n",
      "no_flip: False\n",
      "no_instance: False\n",
      "no_simswaplogo: False\n",
      "norm: batch\n",
      "norm_G: spectralspadesyncbatch3x3\n",
      "ntest: inf\n",
      "onnx: None\n",
      "output_nc: 3\n",
      "output_path: ./output/\n",
      "phase: test\n",
      "pic_a_path: G:/swap_data/ID/elon-musk-hero-image.jpeg\n",
      "pic_b_path: ./demo_file/multi_people.jpg\n",
      "pic_specific_path: ./crop_224/zrf.jpg\n",
      "resize_or_crop: scale_width\n",
      "results_dir: ./results/\n",
      "semantic_nc: 3\n",
      "serial_batches: False\n",
      "temp_path: ./temp_results\n",
      "tf_log: False\n",
      "use_dropout: False\n",
      "use_encoded_image: False\n",
      "use_mask: False\n",
      "verbose: False\n",
      "video_path: G:/swap_data/video/HSB_Demo_Trim.mp4\n",
      "which_epoch: latest\n",
      "-------------- End ----------------\n"
     ]
    }
   ],
   "source": [
    "from options.test_options import TestOptions\n",
    "\n",
    "sys.argv = sys.argv[:1]\n",
    "\n",
    "opt = TestOptions().parse() \n",
    "\n",
    "opt.use_mask = True\n",
    "opt.name = 'people'\n",
    "opt.Arc_path = './checkpoints/arcface_model/arcface_checkpoint.tar'\n",
    "opt.crop_size = 224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "564afc78-a8c8-4e94-8cc4-b0b19cb50074",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tides/SimSwap/util/load_models.py:38: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  netArc = torch.load(Arc_path, map_location=torch.device(\"cpu\"))\n",
      "/home/tides/SimSwap/models/base_model.py:68: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  network.load_state_dict(torch.load(save_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applied providers: ['CUDAExecutionProvider', 'CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}, 'CUDAExecutionProvider': {'sdpa_kernel': '0', 'use_tf32': '1', 'prefer_nhwc': '0', 'tunable_op_max_tuning_duration_ms': '0', 'enable_skip_layer_norm_strict_mode': '0', 'tunable_op_tuning_enable': '0', 'tunable_op_enable': '0', 'use_ep_level_unified_stream': '0', 'device_id': '0', 'has_user_compute_stream': '0', 'gpu_external_empty_cache': '0', 'cudnn_conv_algo_search': 'EXHAUSTIVE', 'cudnn_conv1d_pad_to_nc1d': '0', 'gpu_mem_limit': '18446744073709551615', 'gpu_external_alloc': '0', 'gpu_external_free': '0', 'arena_extend_strategy': 'kNextPowerOfTwo', 'do_copy_in_default_stream': '1', 'enable_cuda_graph': '0', 'user_compute_stream': '0', 'cudnn_conv_use_max_workspace': '1'}}\n",
      "find model: ./checkpoints/models/antelopev2/1k3d68.onnx landmark_3d_68 ['None', 3, 192, 192] 0.0 1.0\n",
      "Applied providers: ['CUDAExecutionProvider', 'CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}, 'CUDAExecutionProvider': {'sdpa_kernel': '0', 'use_tf32': '1', 'prefer_nhwc': '0', 'tunable_op_max_tuning_duration_ms': '0', 'enable_skip_layer_norm_strict_mode': '0', 'tunable_op_tuning_enable': '0', 'tunable_op_enable': '0', 'use_ep_level_unified_stream': '0', 'device_id': '0', 'has_user_compute_stream': '0', 'gpu_external_empty_cache': '0', 'cudnn_conv_algo_search': 'EXHAUSTIVE', 'cudnn_conv1d_pad_to_nc1d': '0', 'gpu_mem_limit': '18446744073709551615', 'gpu_external_alloc': '0', 'gpu_external_free': '0', 'arena_extend_strategy': 'kNextPowerOfTwo', 'do_copy_in_default_stream': '1', 'enable_cuda_graph': '0', 'user_compute_stream': '0', 'cudnn_conv_use_max_workspace': '1'}}\n",
      "find model: ./checkpoints/models/antelopev2/2d106det.onnx landmark_2d_106 ['None', 3, 192, 192] 0.0 1.0\n",
      "Applied providers: ['CUDAExecutionProvider', 'CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}, 'CUDAExecutionProvider': {'sdpa_kernel': '0', 'use_tf32': '1', 'prefer_nhwc': '0', 'tunable_op_max_tuning_duration_ms': '0', 'enable_skip_layer_norm_strict_mode': '0', 'tunable_op_tuning_enable': '0', 'tunable_op_enable': '0', 'use_ep_level_unified_stream': '0', 'device_id': '0', 'has_user_compute_stream': '0', 'gpu_external_empty_cache': '0', 'cudnn_conv_algo_search': 'EXHAUSTIVE', 'cudnn_conv1d_pad_to_nc1d': '0', 'gpu_mem_limit': '18446744073709551615', 'gpu_external_alloc': '0', 'gpu_external_free': '0', 'arena_extend_strategy': 'kNextPowerOfTwo', 'do_copy_in_default_stream': '1', 'enable_cuda_graph': '0', 'user_compute_stream': '0', 'cudnn_conv_use_max_workspace': '1'}}\n",
      "find model: ./checkpoints/models/antelopev2/genderage.onnx genderage ['None', 3, 96, 96] 0.0 1.0\n",
      "Applied providers: ['CUDAExecutionProvider', 'CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}, 'CUDAExecutionProvider': {'sdpa_kernel': '0', 'use_tf32': '1', 'prefer_nhwc': '0', 'tunable_op_max_tuning_duration_ms': '0', 'enable_skip_layer_norm_strict_mode': '0', 'tunable_op_tuning_enable': '0', 'tunable_op_enable': '0', 'use_ep_level_unified_stream': '0', 'device_id': '0', 'has_user_compute_stream': '0', 'gpu_external_empty_cache': '0', 'cudnn_conv_algo_search': 'EXHAUSTIVE', 'cudnn_conv1d_pad_to_nc1d': '0', 'gpu_mem_limit': '18446744073709551615', 'gpu_external_alloc': '0', 'gpu_external_free': '0', 'arena_extend_strategy': 'kNextPowerOfTwo', 'do_copy_in_default_stream': '1', 'enable_cuda_graph': '0', 'user_compute_stream': '0', 'cudnn_conv_use_max_workspace': '1'}}\n",
      "find model: ./checkpoints/models/antelopev2/glintr100.onnx recognition ['None', 3, 112, 112] 127.5 127.5\n",
      "Applied providers: ['CUDAExecutionProvider', 'CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}, 'CUDAExecutionProvider': {'sdpa_kernel': '0', 'use_tf32': '1', 'prefer_nhwc': '0', 'tunable_op_max_tuning_duration_ms': '0', 'enable_skip_layer_norm_strict_mode': '0', 'tunable_op_tuning_enable': '0', 'tunable_op_enable': '0', 'use_ep_level_unified_stream': '0', 'device_id': '0', 'has_user_compute_stream': '0', 'gpu_external_empty_cache': '0', 'cudnn_conv_algo_search': 'EXHAUSTIVE', 'cudnn_conv1d_pad_to_nc1d': '0', 'gpu_mem_limit': '18446744073709551615', 'gpu_external_alloc': '0', 'gpu_external_free': '0', 'arena_extend_strategy': 'kNextPowerOfTwo', 'do_copy_in_default_stream': '1', 'enable_cuda_graph': '0', 'user_compute_stream': '0', 'cudnn_conv_use_max_workspace': '1'}}\n",
      "find model: ./checkpoints/models/antelopev2/scrfd_10g_bnkps.onnx detection [1, 3, '?', '?'] 127.5 128.0\n",
      "set det-size: (640, 640)\n"
     ]
    }
   ],
   "source": [
    "netArc = load_netArc(opt.Arc_path, device)\n",
    "face_swap_model = load_face_swap_model(device, netArc, opt)\n",
    "detect_model = load_insightface_model(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25b9b786-4c2b-4114-bbe3-fcb85ffecfdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_image_path = 'demo_file/source_image/Iron_man.jpg'\n",
    "target_video_path = 'demo_file/target_video/jirou_anni.mp4'\n",
    "result_video_path = 'demo_file/result'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e247df19-47e8-4a99-aba9-58f092be699a",
   "metadata": {},
   "source": [
    "## Source图像处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef76885e-b577-4f96-9281-ebb857e21e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_image = cv2.imread(source_image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd1859bb-f47b-49af-8c41-1365920eec43",
   "metadata": {},
   "outputs": [],
   "source": [
    "from util.face_process import crop_and_align_face\n",
    "from util.data_process import process_latent_id\n",
    "\n",
    "source_crop_align_image, source_M = crop_and_align_face(detect_model, source_image, opt.crop_size)\n",
    "latend_id = process_latent_id(source_crop_align_image, netArc, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96cd60d1-63cb-4498-8bc6-a86908518e18",
   "metadata": {},
   "source": [
    "## Target视频处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb0fd7ba-f6d9-41d7-a4e5-444999c4b59c",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_video = cv2.VideoCapture(target_video_path)\n",
    "target_video.set(cv2.CAP_PROP_POS_FRAMES, 150)\n",
    "\n",
    "ret, frame = target_video.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e07b932c-e2e8-4b5a-b54c-f5db9f57e800",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_crop_align_image, target_M = crop_and_align_face(detect_model, frame, opt.crop_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55bf1dd2-1b5e-4f03-bb1c-041613515556",
   "metadata": {},
   "outputs": [],
   "source": [
    "from util.data_process import process_image_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9635f00-a469-46ad-9e4a-3e6eec84306f",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_crop_align_tensor = process_image_tensor(target_crop_align_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4baff34-cfd8-4109-8d3f-c0d7bb4afc8f",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## 人脸交换"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a3f8430-d5ba-446c-ba59-9357dc8b582d",
   "metadata": {},
   "outputs": [],
   "source": [
    "swap_result = face_swap_model(None, target_crop_align_tensor, latend_id, None, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f17d33f9-2357-4c28-9a36-4e9246d05142",
   "metadata": {},
   "source": [
    "## 图像重建"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "784ad272-21c3-4ca7-8f4b-cd98d1a9f434",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchinfo import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aadf021c-8de3-4ee8-a215-bf5f05bcca56",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "====================================================================================================\n",
       "Layer (type:depth-idx)                             Output Shape              Param #\n",
       "====================================================================================================\n",
       "fsModel                                            [1, 3, 224, 224]          52,193,215\n",
       "├─Generator_Adain_Upsample: 1-1                    --                        --\n",
       "│    └─Sequential: 2-1                             [1, 64, 224, 224]         --\n",
       "│    │    └─ReflectionPad2d: 3-1                   [1, 3, 230, 230]          --\n",
       "│    │    └─Conv2d: 3-2                            [1, 64, 224, 224]         9,472\n",
       "│    │    └─BatchNorm2d: 3-3                       [1, 64, 224, 224]         128\n",
       "│    └─Sequential: 2-31                            --                        (recursive)\n",
       "│    │    └─ReLU: 3-4                              [1, 64, 224, 224]         --\n",
       "│    └─Sequential: 2-3                             [1, 128, 112, 112]        --\n",
       "│    │    └─Conv2d: 3-5                            [1, 128, 112, 112]        73,856\n",
       "│    │    └─BatchNorm2d: 3-6                       [1, 128, 112, 112]        256\n",
       "│    └─Sequential: 2-31                            --                        (recursive)\n",
       "│    │    └─ReLU: 3-7                              [1, 128, 112, 112]        --\n",
       "│    └─Sequential: 2-5                             [1, 256, 56, 56]          --\n",
       "│    │    └─Conv2d: 3-8                            [1, 256, 56, 56]          295,168\n",
       "│    │    └─BatchNorm2d: 3-9                       [1, 256, 56, 56]          512\n",
       "│    └─Sequential: 2-31                            --                        (recursive)\n",
       "│    │    └─ReLU: 3-10                             [1, 256, 56, 56]          --\n",
       "│    └─Sequential: 2-7                             [1, 512, 28, 28]          --\n",
       "│    │    └─Conv2d: 3-11                           [1, 512, 28, 28]          1,180,160\n",
       "│    │    └─BatchNorm2d: 3-12                      [1, 512, 28, 28]          1,024\n",
       "│    └─Sequential: 2-31                            --                        (recursive)\n",
       "│    │    └─ReLU: 3-13                             [1, 512, 28, 28]          --\n",
       "│    └─Sequential: 2-27                            --                        (recursive)\n",
       "│    │    └─ResnetBlock_Adain: 3-14                [1, 512, 28, 28]          5,770,240\n",
       "│    └─Sequential: 2-31                            --                        (recursive)\n",
       "│    │    └─ReLU: 3-15                             [1, 512, 28, 28]          --\n",
       "│    └─Sequential: 2-27                            --                        (recursive)\n",
       "│    │    └─ResnetBlock_Adain: 3-16                --                        (recursive)\n",
       "│    │    └─ResnetBlock_Adain: 3-17                [1, 512, 28, 28]          5,770,240\n",
       "│    └─Sequential: 2-31                            --                        (recursive)\n",
       "│    │    └─ReLU: 3-18                             [1, 512, 28, 28]          --\n",
       "│    └─Sequential: 2-27                            --                        (recursive)\n",
       "│    │    └─ResnetBlock_Adain: 3-19                --                        (recursive)\n",
       "│    │    └─ResnetBlock_Adain: 3-20                [1, 512, 28, 28]          5,770,240\n",
       "│    └─Sequential: 2-31                            --                        (recursive)\n",
       "│    │    └─ReLU: 3-21                             [1, 512, 28, 28]          --\n",
       "│    └─Sequential: 2-27                            --                        (recursive)\n",
       "│    │    └─ResnetBlock_Adain: 3-22                --                        (recursive)\n",
       "│    │    └─ResnetBlock_Adain: 3-23                [1, 512, 28, 28]          5,770,240\n",
       "│    └─Sequential: 2-31                            --                        (recursive)\n",
       "│    │    └─ReLU: 3-24                             [1, 512, 28, 28]          --\n",
       "│    └─Sequential: 2-27                            --                        (recursive)\n",
       "│    │    └─ResnetBlock_Adain: 3-25                --                        (recursive)\n",
       "│    │    └─ResnetBlock_Adain: 3-26                [1, 512, 28, 28]          5,770,240\n",
       "│    └─Sequential: 2-31                            --                        (recursive)\n",
       "│    │    └─ReLU: 3-27                             [1, 512, 28, 28]          --\n",
       "│    └─Sequential: 2-27                            --                        (recursive)\n",
       "│    │    └─ResnetBlock_Adain: 3-28                --                        (recursive)\n",
       "│    │    └─ResnetBlock_Adain: 3-29                [1, 512, 28, 28]          5,770,240\n",
       "│    └─Sequential: 2-31                            --                        (recursive)\n",
       "│    │    └─ReLU: 3-30                             [1, 512, 28, 28]          --\n",
       "│    └─Sequential: 2-27                            --                        (recursive)\n",
       "│    │    └─ResnetBlock_Adain: 3-31                --                        (recursive)\n",
       "│    │    └─ResnetBlock_Adain: 3-32                [1, 512, 28, 28]          5,770,240\n",
       "│    └─Sequential: 2-31                            --                        (recursive)\n",
       "│    │    └─ReLU: 3-33                             [1, 512, 28, 28]          --\n",
       "│    └─Sequential: 2-27                            --                        (recursive)\n",
       "│    │    └─ResnetBlock_Adain: 3-34                --                        (recursive)\n",
       "│    │    └─ResnetBlock_Adain: 3-35                [1, 512, 28, 28]          5,770,240\n",
       "│    └─Sequential: 2-31                            --                        (recursive)\n",
       "│    │    └─ReLU: 3-36                             [1, 512, 28, 28]          --\n",
       "│    └─Sequential: 2-27                            --                        (recursive)\n",
       "│    │    └─ResnetBlock_Adain: 3-37                --                        (recursive)\n",
       "│    │    └─ResnetBlock_Adain: 3-38                [1, 512, 28, 28]          5,770,240\n",
       "│    └─Sequential: 2-31                            --                        (recursive)\n",
       "│    │    └─ReLU: 3-39                             [1, 512, 28, 28]          --\n",
       "│    └─Sequential: 2-27                            --                        (recursive)\n",
       "│    │    └─ResnetBlock_Adain: 3-40                --                        (recursive)\n",
       "│    └─Sequential: 2-28                            [1, 256, 56, 56]          --\n",
       "│    │    └─Upsample: 3-41                         [1, 512, 56, 56]          --\n",
       "│    │    └─Conv2d: 3-42                           [1, 256, 56, 56]          1,179,904\n",
       "│    │    └─BatchNorm2d: 3-43                      [1, 256, 56, 56]          512\n",
       "│    └─Sequential: 2-31                            --                        (recursive)\n",
       "│    │    └─ReLU: 3-44                             [1, 256, 56, 56]          --\n",
       "│    └─Sequential: 2-30                            [1, 128, 112, 112]        --\n",
       "│    │    └─Upsample: 3-45                         [1, 256, 112, 112]        --\n",
       "│    │    └─Conv2d: 3-46                           [1, 128, 112, 112]        295,040\n",
       "│    │    └─BatchNorm2d: 3-47                      [1, 128, 112, 112]        256\n",
       "│    └─Sequential: 2-31                            --                        (recursive)\n",
       "│    │    └─ReLU: 3-48                             [1, 128, 112, 112]        --\n",
       "│    └─Sequential: 2-32                            [1, 64, 224, 224]         --\n",
       "│    │    └─Upsample: 3-49                         [1, 128, 224, 224]        --\n",
       "│    │    └─Conv2d: 3-50                           [1, 64, 224, 224]         73,792\n",
       "│    │    └─BatchNorm2d: 3-51                      [1, 64, 224, 224]         128\n",
       "│    │    └─ReLU: 3-52                             [1, 64, 224, 224]         --\n",
       "│    └─Sequential: 2-33                            [1, 3, 224, 224]          --\n",
       "│    │    └─ReflectionPad2d: 3-53                  [1, 64, 230, 230]         --\n",
       "│    │    └─Conv2d: 3-54                           [1, 3, 224, 224]          9,411\n",
       "│    │    └─Tanh: 3-55                             [1, 3, 224, 224]          --\n",
       "====================================================================================================\n",
       "Total params: 133,211,074\n",
       "Trainable params: 133,211,074\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (G): 48.14\n",
       "====================================================================================================\n",
       "Input size (MB): 0.61\n",
       "Forward/backward pass size (MB): 245.41\n",
       "Params size (MB): 220.21\n",
       "Estimated Total Size (MB): 466.22\n",
       "===================================================================================================="
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 创建输入张量\n",
    "x1 = torch.randn(1, 512)  # 第一个输入 (1, 512)\n",
    "x2 = torch.randn(1, 3, 224, 224)  # 第二个输入 (1, 3, 224, 224)\n",
    "latent_id = torch.randn(1, 512)  # 第三个输入 (1, 512) (根据实际情况修改形状)\n",
    "latent_att = torch.randn(1, 512)  # 第四个输入 (1, 512) (根据实际情况修改形状)\n",
    "\n",
    "# 提供所有输入\n",
    "summary(face_swap_model, input_size=[(1, 512), (1, 3, 224, 224), (1, 512), (1, 512)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "21578c76-0cb7-4f06-9de5-7dcd0ef2195d",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(face_swap_model.state_dict(), 'face_swap_model.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9eea5cff-c588-4ec0-ace0-6b2a02514771",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e7138202-e854-4a94-ae9f-ecf3508119e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter(log_dir='./logs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a752f907-6c51-4cc9-9bb3-c66928254d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建输入张量\n",
    "x1 = torch.randn(1, 512).to(\"cuda\")  # 第一个输入 (1, 512)\n",
    "x2 = torch.randn(1, 3, 224, 224).to(\"cuda\")  \n",
    "latent_att = torch.randn(1, 512).to(\"cuda\")  # 第三个输入 (1, 512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e6bb8d09-07d4-4819-b5a3-b96e99f0faf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data1/tides/new/miniconda3/envs/faceSwap/lib/python3.8/site-packages/torch/onnx/_internal/jit_utils.py:314: UserWarning: Constant folding - Only steps=1 can be constant folded for opset >= 10 onnx::Slice op. Constant folding not applied. (Triggered internally at ../torch/csrc/jit/passes/onnx/constant_fold.cpp:179.)\n",
      "  _C._jit_pass_onnx_node_shape_type_inference(node, params_dict, opset_version)\n",
      "/data1/tides/new/miniconda3/envs/faceSwap/lib/python3.8/site-packages/torch/onnx/utils.py:739: UserWarning: Constant folding - Only steps=1 can be constant folded for opset >= 10 onnx::Slice op. Constant folding not applied. (Triggered internally at ../torch/csrc/jit/passes/onnx/constant_fold.cpp:179.)\n",
      "  _C._jit_pass_onnx_graph_shape_type_inference(\n",
      "/data1/tides/new/miniconda3/envs/faceSwap/lib/python3.8/site-packages/torch/onnx/utils.py:1244: UserWarning: Constant folding - Only steps=1 can be constant folded for opset >= 10 onnx::Slice op. Constant folding not applied. (Triggered internally at ../torch/csrc/jit/passes/onnx/constant_fold.cpp:179.)\n",
      "  _C._jit_pass_onnx_graph_shape_type_inference(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 导出模型为 ONNX 文件\n",
    "torch.onnx.export(\n",
    "    face_swap_model,                        # 模型\n",
    "    (x1, x2, latent_att),                   # 模型的 3 个输入\n",
    "    \"face_swap_model.onnx\",                 # 导出文件名\n",
    "    export_params=True,                     # 是否存储模型的参数\n",
    "    opset_version=11,                       # ONNX opset 版本\n",
    "    input_names=[\"x1\", \"x2\", \"latent_att\"], # 定义输入名称\n",
    "    output_names=[\"output\"],                # 定义输出名称\n",
    "    dynamic_axes={                          # 动态轴（可选）\n",
    "        \"x1\": {0: \"batch_size\"}, \n",
    "        \"x2\": {0: \"batch_size\"},\n",
    "        \"latent_att\": {0: \"batch_size\"},\n",
    "        \"output\": {0: \"batch_size\"}\n",
    "    }\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdb4f8f3-340e-4173-a945-e5cb77dd0b1e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (faceSwap)",
   "language": "python",
   "name": "faceswap"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
